<!DOCTYPE html>
<html>
<head>
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta http-equiv="content-type" content="text/html; charset=utf-8">
<!-- Enable responsiveness on mobile devices-->
<!-- viewport-fit=cover is to support iPhone X rounded corners and notch in landscape-->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1, viewport-fit=cover">

<title>bjornruud.net</title>

<link rel="stylesheet" href="/print.css" media="print">
<link rel="stylesheet" href="/main.css">


<link rel="alternate" type="application/atom+xml" title="RSS" href="/atom.xml">


  
</head>

<body>
  <div class="flex-container">
    <div class="header-container">
      <div class="header">
        
        <div class="header-title">
  <a href="/">bjornruud.net</a>
</div>
<div class="header-subtitle">
  <a href="/atom.xml">rss</a> |
  <a href="/blog/archive/">archive</a>
</div>

        
      </div>
    </div>

    <div class="content-container">
      <div class="content">
        
<article>
  <div class="date">2009-10-17</div>
  <div class="post">
    <h1 id="batch-image-download-with-wget">Batch Image Download With wget</h1>
<p><a rel="noopener" target="_blank" href="http://www.gnu.org/software/wget/">wget</a> is often used to download single files from the command line, but it can also mirror a website locally or just download part of a website. By specifying the right parameters we can make wget act as batch downloader, retrieving only the files we want.</p>
<p>In this example we assume a website with a sequence of pages, where each page links to the next in the sequence and they all contain a JPEG image. We want to download all the images to the current directory. The following command line does this:</p>
<pre style="background-color:#1e1e1e;color:#dcdcdc;"><code><span>$ wget --recursive --level=inf --no-directories --no-parent --accept *.jpg URL</span><span>
</span></code></pre>
<p>Or if you prefer, the shorter but more obscure:</p>
<pre style="background-color:#1e1e1e;color:#dcdcdc;"><code><span>$ wget -r -l inf -nd -np -A *.jpg URL</span><span>
</span></code></pre>
<p>Let’s take a look at the parameters:</p>
<pre style="background-color:#1e1e1e;color:#dcdcdc;"><code><span>--recursive</span><span>
</span><span>    Makes wget follow links from the start page.</span><span>
</span><span>
</span><span>--level=inf</span><span>
</span><span>    This allows for infinite recursion. In combination with another option that limits the</span><span>
</span><span>    recursion depth, like –no-parent, we don’t need to know the necessary depth. Otherwise</span><span>
</span><span>    you should specify a number to set a limit.</span><span>
</span><span>
</span><span>--no-directories</span><span>
</span><span>    Default behaviour is to recreate the directory structure of the website. This option</span><span>
</span><span>    makes wget put all files in the same directory.</span><span>
</span><span>
</span><span>--no-parent</span><span>
</span><span>    Do not follow links to pages above the starting page in the hierarchy.</span><span>
</span><span>
</span><span>--accept *.jpg</span><span>
</span><span>    Here we specify what kind of file to download. The parameter can be a comma-separated list.</span><span>
</span></code></pre>
<p>For other options and details about those listed here, check the wget man page.</p>
<hr />
<p>In one scenario I used wget the files had to be zero padded (like <code>img-01.jpg</code> instead of <code>img-1.jpg</code>). For a single directory this did the job (for filenames with two digits):</p>
<pre style="background-color:#1e1e1e;color:#dcdcdc;"><code><span>$ rename &#39;s/-([0-9])\./-0$1\./&#39; *.jpg</span><span>
</span></code></pre>
<p>For a directory tree this was used:</p>
<pre style="background-color:#1e1e1e;color:#dcdcdc;"><code><span>$ find . &quot;*.jpg&quot; -type f -print0 | xargs --null rename &#39;s/-([0-9])\./-0$1\./&#39;</span><span>
</span></code></pre>

  </div>
</article>

      </div>
    </div>

    <div class="footer-container">
      <div class="footer">
        
        Bjørn Olav Ruud &copy; 2021<br/>
<a href="https://github.com/BjornRuud">GitHub</a> | <a href="https://www.linkedin.com/in/bjornruud/">LinkedIn</a> | <a href="https://twitter.com/BjornRuud">Twitter</a><br/>
Built with <a href="https://www.getzola.org" target="_blank">Zola</a>

        
      </div>
    </div>
  </div>

  <script data-goatcounter="https://bjornruud.goatcounter.com/count"
  async src="//gc.zgo.at/count.js"></script>
</body>
</html>
